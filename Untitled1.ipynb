{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest path follower with ego_map visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-27 17:16:22,759 Initializing dataset VLN-CE-v1\n",
      "2020-05-27 17:16:23,626 [construct_envs] Using GPU ID 0\n"
     ]
    }
   ],
   "source": [
    "from vlnce_baselines.common.env_utils import construct_envs\n",
    "from habitat import Config\n",
    "from vlnce_baselines.config.default import get_config\n",
    "from habitat_baselines.common.environments import get_env_class\n",
    "\n",
    "\n",
    "\n",
    "#Import config and perform some manipulation\n",
    "exp_config ='vlnce_baselines/config/paper_configs/seq2seq.yaml'\n",
    "config = get_config(exp_config, None)\n",
    "split = config.TASK_CONFIG.DATASET.SPLIT\n",
    "config.defrost()\n",
    "config.TASK_CONFIG.TASK.NDTW.SPLIT = split\n",
    "config.TASK_CONFIG.TASK.SDTW.SPLIT = split\n",
    "\n",
    "# if doing teacher forcing, don't switch the scene until it is complete\n",
    "if config.DAGGER.P == 1.0:\n",
    "    config.TASK_CONFIG.ENVIRONMENT.ITERATOR_OPTIONS.MAX_SCENE_REPEAT_STEPS = (\n",
    "        -1\n",
    "    )\n",
    "config.freeze()\n",
    "envs = construct_envs(config, get_env_class(config.ENV_NAME))\n",
    "# obs=envs.reset()\n",
    "# print(obs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_grid(imgs, grid_size):\n",
    "    h, w = grid_size\n",
    "    img_h, img_w, img_c = imgs[0].shape\n",
    "\n",
    "    m_x = 0\n",
    "    m_y = 0\n",
    "\n",
    "    imgmatrix = np.zeros((img_h * h + m_y * (h - 1),\n",
    "                          img_w * w + m_x * (w - 1),\n",
    "                          img_c),\n",
    "                         np.uint8)\n",
    "\n",
    "    imgmatrix.fill(255)    \n",
    "\n",
    "    positions = itertools.product(range(w), range(h))\n",
    "    for (x_i, y_i), img in zip(positions, imgs):\n",
    "        x = x_i * (img_w + m_x)\n",
    "        y = y_i * (img_h + m_y)\n",
    "        if img.shape[-1] > img_c:\n",
    "            img = img[..., :img_c]\n",
    "        imgmatrix[y:y+img_h, x:x+img_w, :] = img\n",
    "\n",
    "    return imgmatrix\n",
    "\n",
    "\n",
    "def next_perfect_square(N): \n",
    "    sqrt = math.sqrt(N)\n",
    "    next_ = math.floor(sqrt)\n",
    "    if next_ < sqrt:\n",
    "        next_ += 1\n",
    "    return next_\n",
    "\n",
    "\n",
    "def get_grid_size(N):\n",
    "    grid = (2, 3)\n",
    "    if N < 4:\n",
    "        grid = (1, 3)\n",
    "    elif N > 6:\n",
    "        square = next_perfect_square(N)\n",
    "        grid = (square, square)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "\n",
    "def concatentate_and_write_video(observations,\n",
    "                                 directory_to_save_video='./',\n",
    "                                 video_filename='vid.mp4'):\n",
    "    output_shape = observations[0][0].shape[:2]\n",
    "    num_observations = len(observations[0])\n",
    "    if num_observations == 1:\n",
    "        output_all = [cv2.resize(obs[0], output_shape) for obs in observations]\n",
    "    else:\n",
    "        grid_size = get_grid_size(num_observations)\n",
    "        observations = [[cv2.resize(o, output_shape) for o in obs] for obs in observations]\n",
    "        output_all = [images_to_grid(obs, grid_size)\n",
    "                        for obs in observations]\n",
    "\n",
    "    images_to_video(output_all,\n",
    "                    directory_to_save_video,\n",
    "                    video_filename)\n",
    "\n",
    "def save_map(observations, info, images):\n",
    "    im = observations[\"rgb\"]\n",
    "    top_down_map = draw_top_down_map(\n",
    "        info, observations[\"heading\"], im.shape[0]\n",
    "    )\n",
    "    output_im = np.concatenate((im, top_down_map), axis=1)\n",
    "    output_im = append_text_to_image(\n",
    "        output_im, observations[\"instruction\"][\"text\"]\n",
    "    )\n",
    "    images.append(output_im)\n",
    "    \n",
    "def draw_top_down_map(info, heading, output_size):\n",
    "    top_down_map = maps.colorize_topdown_map(\n",
    "        info[\"top_down_map\"][\"map\"], info[\"top_down_map\"][\"fog_of_war_mask\"]\n",
    "    )\n",
    "    original_map_size = top_down_map.shape[:2]\n",
    "    map_scale = np.array(\n",
    "        (1, original_map_size[1] * 1.0 / original_map_size[0])\n",
    "    )\n",
    "    new_map_size = np.round(output_size * map_scale).astype(np.int32)\n",
    "    # OpenCV expects w, h but map size is in h, w\n",
    "    top_down_map = cv2.resize(top_down_map, (new_map_size[1], new_map_size[0]))\n",
    "\n",
    "    map_agent_pos = info[\"top_down_map\"][\"agent_map_coord\"]\n",
    "    map_agent_pos = np.round(\n",
    "        map_agent_pos * new_map_size / original_map_size\n",
    "    ).astype(np.int32)\n",
    "    top_down_map = maps.draw_agent(\n",
    "        top_down_map,\n",
    "        map_agent_pos,\n",
    "        heading - np.pi / 2,\n",
    "        agent_radius_px=top_down_map.shape[0] / 40,\n",
    "    )\n",
    "    return top_down_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b1c961237702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mIMAGE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"examples\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m follower = ShortestPathFollower(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhabitat_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_radius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_one_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0mfollower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from habitat.tasks.nav.shortest_path_follower import ShortestPathFollower\n",
    "IMAGE_DIR = os.path.join(\"examples\", \"images\")\n",
    "follower = ShortestPathFollower(\n",
    "    env.habitat_env.sim, goal_radius=0.5, return_one_hot=False\n",
    ")\n",
    "follower.mode = mode\n",
    "print(\"Environment creation successful\")\n",
    "\n",
    "for episode in range(1):\n",
    "    obs=envs.reset()\n",
    "    print(obs)\n",
    "    print(\"\\n\")\n",
    "    episode = current_episodes()\n",
    "    episode_id = episode[0].episode_id\n",
    "    print(\n",
    "        f\"Agent stepping around inside environment. Episode id: {episode_id}\"\n",
    "    )\n",
    "\n",
    "    dirname = os.path.join(\n",
    "        IMAGE_DIR, \"vln_reference_path_example\", mode, \"%02d\" % episode\n",
    "    )\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.makedirs(dirname)\n",
    "\n",
    "    images = []\n",
    "    steps = 0\n",
    "    reference_path = episode[0].reference_path + [\n",
    "        episode[0].goals[0].position\n",
    "    ]\n",
    "    for point in reference_path:\n",
    "        done = False\n",
    "        while not done:\n",
    "            best_action = follower.get_next_action(point)\n",
    "            if best_action == None or best_action ==0:\n",
    "                break\n",
    "            observations, reward, done, info = envs.step(best_action)\n",
    "            \n",
    "            semantic_obs = observation[0]['semantic'] #128*128 - will return instance segmentation\n",
    "            ego_map= observation[0]['ego_sem_map'] # 40 * 40 ego centric version. \n",
    "            \n",
    "            object2idx = envs.call_at(0,'get_object2idx')\n",
    "            semantic_obs = object2idx[semantic_obs] \n",
    "            ego_map = object2idx[ego_map.astype(np.int)]\n",
    "            \n",
    "            ego_img= semantic_to_image(ego_map)\n",
    "            semantic_img = semantic_to_image(semantic_obs)\n",
    "            \n",
    "            save_map(observations[0], info[0], images)\n",
    "            images.append([ semantic_img,\n",
    "                                 ego_img])\n",
    "            steps += 1\n",
    "    envs.close()\n",
    "    \n",
    "    print(f\"Navigated to goal in {steps} steps.\")\n",
    "    concatentate_and_write_video(images, directory_to_save_video=os.getcwd(), video_filename=\"ego_semantic_map\")\n",
    "    images_to_video(images, dirname, str(episode_id))\n",
    "    images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "habitat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
